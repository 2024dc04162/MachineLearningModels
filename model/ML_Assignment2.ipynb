{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412bac68-a723-4329-a4d6-017994fe2879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Accuracy       AUC  Precision  Recall  F1 Score       MCC\n",
      "Logistic Regression    0.9650  0.998667   0.965045  0.9650  0.964986  0.953357\n",
      "Decision Tree          0.8300  0.886667   0.831883  0.8300  0.830168  0.773811\n",
      "KNN                    0.5000  0.769750   0.521130  0.5000  0.505355  0.334993\n",
      "Naive Bayes            0.8100  0.950567   0.811326  0.8100  0.810458  0.746804\n",
      "Random Forest          0.8775  0.979608   0.877649  0.8775  0.877400  0.836785\n",
      "XGBoost                0.9225  0.993842   0.922631  0.9225  0.922482  0.896719\n"
     ]
    }
   ],
   "source": [
    "#Setup and imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score,\n",
    "    recall_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Loading the data set\n",
    "\n",
    "train_path= r\"C:\\Users\\HP\\Documents\\ML\\mobile_train.csV\"\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "X = train_df.drop(\"price_range\", axis=1)\n",
    "y = train_df[\"price_range\"]\n",
    "\n",
    "\n",
    "#Train - Test Splitting\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#Feature Scaling for LR & KNN\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Model Training & Evaluation - Helper function for Metrics\n",
    "\n",
    "def evaluate_model(model, X_tr, X_te):\n",
    "    model.fit(X_tr, y_train)\n",
    "    y_pred = model.predict(X_te)\n",
    "    y_prob = model.predict_proba(X_te)\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"AUC\": roc_auc_score(y_test, y_prob, multi_class=\"ovr\"),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average=\"weighted\"),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average=\"weighted\"),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, average=\"weighted\"),\n",
    "        \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "#Logistic Regression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr_results = evaluate_model(lr, X_train_scaled, X_test_scaled)\n",
    "\n",
    "#Decision Tree Classifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt_results = evaluate_model(dt, X_train, X_test)\n",
    "\n",
    "#KNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_results = evaluate_model(knn, X_train_scaled, X_test_scaled)\n",
    "\n",
    "#Naive Bayes ( Gaussian)\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb_results = evaluate_model(nb, X_train, X_test)\n",
    "\n",
    "#Random Forest (Ensemble)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_results = evaluate_model(rf, X_train, X_test)\n",
    "\n",
    "#XGBoost (Ensemble)\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    objective=\"multi:softprob\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_results = evaluate_model(xgb, X_train, X_test)\n",
    "\n",
    "#Comparision Table\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Logistic Regression\": lr_results,\n",
    "    \"Decision Tree\": dt_results,\n",
    "    \"KNN\": knn_results,\n",
    "    \"Naive Bayes\": nb_results,\n",
    "    \"Random Forest\": rf_results,\n",
    "    \"XGBoost\": xgb_results\n",
    "}).T\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073bd5a1-1f66-4797-b9af-4d966837cb03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
